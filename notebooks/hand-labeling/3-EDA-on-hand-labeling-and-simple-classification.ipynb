{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA on hand-labeling and simple classification\n",
    "\n",
    "In this notebook, I will start by doing exploratory data analysis on the labeled sentences. For example:\n",
    "1. How many did I label of each category?\n",
    "2. For each category, what percentage of sentences were labeled in that category?\n",
    "3. How many sentences were just labeled as 'Other'?\n",
    "\n",
    "I will find that for all 7 of the 10 bins (one for each category and PRO/CON), I labeled less than $20\\%$ of the review sentences in that bin. Thus, class imbalance is something we need to consider when classifying.\n",
    "\n",
    "Then I will do some classification with a Word2Vec model trained on the hand-labeled data. For my model, I will compare the performances of Logistic Regression and Random Forest Classifiers. I will also do Grid Search with Stratified K-fold cross validation (due to class imbalance). I will find that the recall is very low, hence these models will not be sufficient for our desires, but it will still be a useful baseline to improve from. Also, I'll find that Logistic Regression perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.testing import assert_array_equal\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#set default seaborn plotting style\n",
    "sns.set_style('white')\n",
    "\n",
    "import time\n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import hand-labeled PROs and CONs sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all 1993 hand-labeled PROs sentences\n",
    "pros_sentences = pd.read_csv('pros_sentences_labeled.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all 2000 hand-labeled CONs sentences\n",
    "cons_sentences = pd.read_csv('cons_sentences_labeled.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency of labeled reviews by category\n",
    "\n",
    "For each of 10 bins (one for each category and PRO/CON), I will calculate the frequency and percentage of sentences that were labeled to be in that bin. I will find that there is some major class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pros (1 if sentence labeled in category, 0 otherwise)\n",
      "--------------------------------------------------\n",
      "Culture & Values\n",
      "Frequency:\n",
      "0    1267\n",
      "1     726\n",
      "Name: Culture & Values, dtype: int64\n",
      "Percentages:\n",
      "0    63.572504\n",
      "1    36.427496\n",
      "Name: Culture & Values, dtype: float64\n",
      "--------------------------------------------------\n",
      "Work/Life Balance\n",
      "Frequency:\n",
      "0    1734\n",
      "1     259\n",
      "Name: Work/Life Balance, dtype: int64\n",
      "Percentages:\n",
      "0    87.004516\n",
      "1    12.995484\n",
      "Name: Work/Life Balance, dtype: float64\n",
      "--------------------------------------------------\n",
      "Senior Management\n",
      "Frequency:\n",
      "0    1822\n",
      "1     171\n",
      "Name: Senior Management, dtype: int64\n",
      "Percentages:\n",
      "0    91.41997\n",
      "1     8.58003\n",
      "Name: Senior Management, dtype: float64\n",
      "--------------------------------------------------\n",
      "Comp & Benefits\n",
      "Frequency:\n",
      "0    1351\n",
      "1     642\n",
      "Name: Comp & Benefits, dtype: int64\n",
      "Percentages:\n",
      "0    67.787255\n",
      "1    32.212745\n",
      "Name: Comp & Benefits, dtype: float64\n",
      "--------------------------------------------------\n",
      "Career Opportunities\n",
      "Frequency:\n",
      "0    1617\n",
      "1     376\n",
      "Name: Career Opportunities, dtype: int64\n",
      "Percentages:\n",
      "0    81.133969\n",
      "1    18.866031\n",
      "Name: Career Opportunities, dtype: float64\n",
      "--------------------------------------------------\n",
      "Other\n",
      "Frequency:\n",
      "0    1680\n",
      "1     313\n",
      "Name: Other, dtype: int64\n",
      "Percentages:\n",
      "0    84.295033\n",
      "1    15.704967\n",
      "Name: Other, dtype: float64\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pros_categories = ['Culture & Values', 'Work/Life Balance', 'Senior Management',\n",
    "       'Comp & Benefits', 'Career Opportunities', 'Other']\n",
    "\n",
    "print('Pros (1 if sentence labeled in category, 0 otherwise)')\n",
    "print('-'*50)\n",
    "\n",
    "for cat in pros_categories:\n",
    "    print(cat)\n",
    "    print('Frequency:')\n",
    "    print(pros_sentences.loc[:,cat].value_counts())\n",
    "    print('Percentages:')\n",
    "    print(pros_sentences.loc[:,cat].value_counts()/pros_sentences.shape[0]*100)\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cons (1 if sentence labeled in category, 0 otherwise)\n",
      "--------------------------------------------------\n",
      "Culture & Values\n",
      "Frequency:\n",
      "0    1312\n",
      "1     688\n",
      "Name: Culture & Values, dtype: int64\n",
      "Percentages:\n",
      "0    65.6\n",
      "1    34.4\n",
      "Name: Culture & Values, dtype: float64\n",
      "--------------------------------------------------\n",
      "Work/Life Balance\n",
      "Frequency:\n",
      "0    1764\n",
      "1     236\n",
      "Name: Work/Life Balance, dtype: int64\n",
      "Percentages:\n",
      "0    88.2\n",
      "1    11.8\n",
      "Name: Work/Life Balance, dtype: float64\n",
      "--------------------------------------------------\n",
      "Senior Management\n",
      "Frequency:\n",
      "0    1697\n",
      "1     303\n",
      "Name: Senior Management, dtype: int64\n",
      "Percentages:\n",
      "0    84.85\n",
      "1    15.15\n",
      "Name: Senior Management, dtype: float64\n",
      "--------------------------------------------------\n",
      "Comp & Benefits\n",
      "Frequency:\n",
      "0    1705\n",
      "1     295\n",
      "Name: Comp & Benefits, dtype: int64\n",
      "Percentages:\n",
      "0    85.25\n",
      "1    14.75\n",
      "Name: Comp & Benefits, dtype: float64\n",
      "--------------------------------------------------\n",
      "Career Opportunities\n",
      "Frequency:\n",
      "0    1668\n",
      "1     332\n",
      "Name: Career Opportunities, dtype: int64\n",
      "Percentages:\n",
      "0    83.4\n",
      "1    16.6\n",
      "Name: Career Opportunities, dtype: float64\n",
      "--------------------------------------------------\n",
      "Technology\n",
      "Frequency:\n",
      "0    1947\n",
      "1      53\n",
      "Name: Technology, dtype: int64\n",
      "Percentages:\n",
      "0    97.35\n",
      "1     2.65\n",
      "Name: Technology, dtype: float64\n",
      "--------------------------------------------------\n",
      "Other\n",
      "Frequency:\n",
      "0    1505\n",
      "1     495\n",
      "Name: Other, dtype: int64\n",
      "Percentages:\n",
      "0    75.25\n",
      "1    24.75\n",
      "Name: Other, dtype: float64\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cons_categories = ['Culture & Values', 'Work/Life Balance', 'Senior Management',\n",
    "       'Comp & Benefits', 'Career Opportunities', 'Technology', 'Other']\n",
    "\n",
    "print('Cons (1 if sentence labeled in category, 0 otherwise)')\n",
    "print('-'*50)\n",
    "\n",
    "for cat in cons_categories:\n",
    "    print(cat)\n",
    "    print('Frequency:')\n",
    "    print(cons_sentences.loc[:,cat].value_counts())\n",
    "    print('Percentages:')\n",
    "    print(cons_sentences.loc[:,cat].value_counts()/cons_sentences.shape[0]*100)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove 'Technology' as a category. There are only 53 Cons sentences labeled as such. That may not be enough to create a meaningful prediction of if a sentence is concerned about 'Technology'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word tokenize sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize_a_sentence(sentence, tokenizer_input):\n",
    "    '''\n",
    "    Remove stopwords, make lowercase and tokenize.\n",
    "    \n",
    "    Args:\n",
    "        sentence\n",
    "    \n",
    "    Returns:\n",
    "        Sentence with stop words removed and made lowercase. For example:\n",
    "            \"You are my best Friend\" --> [\"are\", \"best\", \"friend\"]            \n",
    "    '''\n",
    "        \n",
    "    sentence = ' '.join([word.lower() for word in sentence.split() if word not in stop_words])\n",
    "    \n",
    "    return tokenizer_input.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column of tokens for each sentence\n",
    "pros_sentences.loc[:,'tokens'] = pros_sentences.loc[:,'PROs_sentence'].\\\n",
    "    apply(lambda sentence: tokenize_a_sentence(sentence, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Representation of sentences\n",
    "\n",
    "We now need to find Word2Vec representation of each labeled sentence. To do this, we need to find the representation of every word. The representation of a sentence will be given by the average of the sentences words (modulo stop words).\n",
    "\n",
    "I originally tried to use a pretrained Word2Vec model via Glove, but it didn't contain common words, like 'opportunity' and 'benefits.' Thus, I will train a own model using the PROs and CONs sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of dimensions for Word2Vec model\n",
    "dim = 100\n",
    "\n",
    "#train Word2Vec model on tokens\n",
    "model = gensim.models.Word2Vec(list(pros_sentences.loc[:,'tokens']), size=dim)\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that it contains some commonly used words\n",
    "assert(model.wv.__contains__('opportunity'))\n",
    "assert(model.wv.__contains__('work'))\n",
    "assert(model.wv.__contains__('benefits'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_of_tokens(tokens):\n",
    "    '''\n",
    "    Computes average of list of tokens' vector representations.\n",
    "    \n",
    "    Args:\n",
    "        List of word tokens\n",
    "    \n",
    "    Returns:\n",
    "        100-dimensional vector\n",
    "    '''\n",
    "    return np.array([np.mean([model[w] for w in tokens if w in model]\n",
    "                            or [np.zeros(dim)], axis=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize pros sentences from sample of 1993\n",
    "\n",
    "We will vectorize all of the sentences from our sample of 1993."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derekjung/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:11: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "/Users/derekjung/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "pros_sentences_vectors_array = np.zeros((pros_sentences.shape[0], dim))\n",
    "\n",
    "\n",
    "#store vectorizations of sentences in 100-column array\n",
    "for idx in range(pros_sentences.shape[0]):\n",
    "    pros_sentences_vectors_array[idx] = average_of_tokens(pros_sentences.loc[idx,'tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derekjung/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:11: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "/Users/derekjung/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "#see that first row matches what we expect (representation of first pro sentence)\n",
    "assert_array_equal(pros_sentences_vectors_array[0], \n",
    "                   average_of_tokens(pros_sentences.loc[0,'tokens']).reshape((100,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that array has right shape (number of pros sentences x vector dimension)\n",
    "assert(pros_sentences_vectors_array.shape == (pros_sentences.shape[0], dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store Word2Vec sentence vectors as DataFrame\n",
    "pros_sentences_vectors_df = pd.DataFrame(pros_sentences_vectors_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Culture & Values with Logistic Regression\n",
    "\n",
    "I will try to find the best classification for predicting labels. I will start by trying to predict whether a PROs sentence is related to 'Culture & Values.'\n",
    "\n",
    "We see (in the next plot) that our data is clustered around 0. To make our model more effective, we will use a Standard Scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFJCAYAAABKLF7JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLPB/8vk/z+pEdqcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#roughly compare distributions of first three Word2Vec features\n",
    "for idx in range(3):\n",
    "    pros_sentences_vectors_df.loc[:,idx].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for C: [1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
      " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
      " 1.00000000e+01 3.16227766e+01 1.00000000e+02 3.16227766e+02\n",
      " 1.00000000e+03 3.16227766e+03 1.00000000e+04 3.16227766e+04\n",
      " 1.00000000e+05 3.16227766e+05 1.00000000e+06 3.16227766e+06\n",
      " 1.00000000e+07 3.16227766e+07 1.00000000e+08 3.16227766e+08\n",
      " 1.00000000e+09 3.16227766e+09 1.00000000e+10]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression pipeline\n",
    "lrp = Pipeline([('ss', StandardScaler()),\n",
    "               ('lr', LogisticRegression(random_state=23))])\n",
    "\n",
    "#C values for Logistic Regression\n",
    "c_vals = np.logspace(-3,10,27)\n",
    "\n",
    "print('Values for C: {}'.format(c_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reserve 75% of data for training\n",
    "#stratify to make sure that equal representation of Culture & Values \n",
    "x_train_culture, x_test_culture, y_train_culture, y_test_culture = \\\n",
    "    train_test_split(pros_sentences_vectors_df, \n",
    "                     pros_sentences.loc[:,'Culture & Values'],\n",
    "                    test_size=0.25,\n",
    "                     stratify=pros_sentences.loc[:,'Culture & Values'],\n",
    "                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do k-fold cross-validation to maintain class balance\n",
    "skf = StratifiedKFold(n_splits=5, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 LogisticRegression models took 16.060067176818848 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#create arrays to hold cross-validation stats\n",
    "scr_mean_culture = np.zeros(c_vals.shape)\n",
    "scr_std_culture = np.zeros(c_vals.shape)\n",
    "\n",
    "for idx, c in enumerate(c_vals):\n",
    "    lrp.set_params(lr__C = c)\n",
    "    score = cross_val_score(lrp, x_train_culture, y_train_culture, cv=skf)\n",
    "    scr_mean_culture[idx] = np.mean(score)\n",
    "    scr_std_culture[idx] = np.std(score)\n",
    "    \n",
    "print('{} LogisticRegression models took {} seconds'.format(c_vals.shape[0], \n",
    "                                                            str(time.time() - start_time))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score = 0.722 +/- 0.011\n",
      "Best C param = 10.000\n"
     ]
    }
   ],
   "source": [
    "#find best score\n",
    "idx = np.argmax(scr_mean_culture)\n",
    "\n",
    "#display best score with error and associated 'C\" value\n",
    "\n",
    "print(f'Best score = {scr_mean_culture[idx]:5.3f} +/- {scr_std_culture[idx]:5.3f}')\n",
    "print(f'Best C param = {c_vals[idx]:5.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.87      0.82       317\n",
      "          1       0.72      0.55      0.63       182\n",
      "\n",
      "avg / total       0.75      0.76      0.75       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now perform standard performance testing by creating and applying model to test data\n",
    "\n",
    "#set parameter to best value\n",
    "lrp.set_params(lr__C = c_vals[idx])\n",
    "\n",
    "#Train model and predict on test data\n",
    "lrp.fit(x_train_culture, y_train_culture)\n",
    "y_pred_culture = lrp.predict(x_test_culture)\n",
    "\n",
    "#Generate classification report\n",
    "print(classification_report(y_test_culture,y_pred_culture))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAIzCAYAAABbZI5DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Define confidence interval\n",
    "high = scr_mean_culture + scr_std_culture\n",
    "low = scr_mean_culture - scr_std_culture\n",
    "\n",
    "#plot results\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "# Plot confidence interval\n",
    "ax.semilogx(c_vals, scr_mean_culture,\n",
    "           color = sns.xkcd_rgb[\"denim blue\"], linewidth=4)\n",
    "ax.fill_between(c_vals, high, low,\n",
    "               color=sns.xkcd_rgb['dusty purple'], alpha=0.25)\n",
    "\n",
    "# Mark the best 'C' value\n",
    "ax.vlines(c_vals[idx], 0.6, 0.8, linestyles='-.',\n",
    "         color = sns.xkcd_rgb[\"pale red\"])\n",
    "ax.text(c_vals[idx], 0.85, 'Best Value',\n",
    "       horizontalalignment='center',\n",
    "       verticalalignment='top')\n",
    "\n",
    "#Decorate plot\n",
    "ax.set(title='LR Parameter Selection',\n",
    "      xlabel='C parameter',\n",
    "      ylabel='CV Score',\n",
    "      ylim=(0.5, 0.8))\n",
    "\n",
    "#ax.legend(loc=4, borderaxespad=1.5)\n",
    "sns.despine(offset=5, trim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Random Forests and GridSearchCV\n",
    "\n",
    "I will now compare the previous performance with that using Random Forest Classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make Random Forest Classifier pipeline\n",
    "rfcp = Pipeline([('ss', StandardScaler()),\n",
    "               ('rfc', RandomForestClassifier(random_state=23))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 56.76226592063904 seconds to train 7 RFC\"s\n",
      "Best number of estimators = 140.0000\n",
      "Best CV Score = 0.688\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#create dictionary of hyperparameters\n",
    "#n_estimators = [10, 20, 50, 100, 150, 200, 250, 300] #find best number of estimators at 150\n",
    "n_estimators = [120, 130, 140, 150, 160, 170, 180]\n",
    "params = dict(rfc__n_estimators=n_estimators)\n",
    "\n",
    "#create grid search cross validator\n",
    "gse = GridSearchCV(estimator=rfcp, param_grid=params, cv=skf)\n",
    "\n",
    "#fit estimator\n",
    "gse.fit(x_train_culture, y_train_culture)\n",
    "\n",
    "#Display time and best estimator results\n",
    "print('Took {} seconds to train {} RFC\"s'.format(time.time() - start_time, \n",
    "                                                 len(n_estimators)))\n",
    "\n",
    "print('Best number of estimators = {0:5.4f}'.format(gse.best_estimator_.get_params()['rfc__n_estimators']))\n",
    "print('Best CV Score = {0:4.3f}'.format(gse.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.90      0.79       317\n",
      "          1       0.65      0.34      0.45       182\n",
      "\n",
      "avg / total       0.68      0.69      0.66       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfcp.set_params(rfc__n_estimators = 160)\n",
    "\n",
    "rfcp.fit(x_train_culture, y_train_culture)\n",
    "y_pred = rfcp.predict(x_test_culture)\n",
    "\n",
    "print(classification_report(y_test_culture, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Work/Life Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-03, 3.16227766e-03, 1.00000000e-02, 3.16227766e-02,\n",
       "       1.00000000e-01, 3.16227766e-01, 1.00000000e+00, 3.16227766e+00,\n",
       "       1.00000000e+01, 3.16227766e+01, 1.00000000e+02, 3.16227766e+02,\n",
       "       1.00000000e+03, 3.16227766e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vals = np.logspace(-3,4,15)\n",
    "\n",
    "c_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_worklife, x_test_worklife, y_train_worklife, y_test_worklife = \\\n",
    "        train_test_split(pros_sentences_vectors_df, \n",
    "                         pros_sentences.loc[:,'Work/Life Balance'],\n",
    "                         test_size=0.25,\n",
    "                         stratify=pros_sentences.loc[:,'Work/Life Balance'],\n",
    "                         random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 15 Logistic Regression models took 6.406237363815308 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#create arrays to hold CV stats\n",
    "scr_mean_worklife = np.zeros(c_vals.shape)\n",
    "scr_std_worklife = np.zeros(c_vals.shape)\n",
    "\n",
    "for idx, c in enumerate(c_vals):\n",
    "    lrp.set_params(lr__C = c)\n",
    "    score = cross_val_score(lrp, x_train_worklife, y_train_worklife, cv=skf)\n",
    "    scr_mean_worklife[idx] = np.mean(score)\n",
    "    scr_std_worklife[idx] = np.std(score)\n",
    "    \n",
    "print('Training {} Logistic Regression models took {} seconds'.format(c_vals.shape[0], \n",
    "                                                                      str(time.time()-start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score = 0.902 +/- 0.013\n",
      "Best C param = 3.162\n"
     ]
    }
   ],
   "source": [
    "idx = np.argmax(scr_mean_worklife)\n",
    "\n",
    "#display best score with error and associated 'C' value\n",
    "\n",
    "print('Best score = {0:5.3f} +/- {1:5.3f}'.format(scr_mean_worklife[idx], scr_std_worklife[idx]))\n",
    "print('Best C param = {0:5.3f}'.format(c_vals[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 89.579%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       434\n",
      "          1       0.68      0.38      0.49        65\n",
      "\n",
      "avg / total       0.88      0.90      0.88       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now perform standard performance testing by creating and applying model to test data\n",
    "\n",
    "#set parameter to best value\n",
    "lrp.set_params(lr__C = c_vals[idx])\n",
    "\n",
    "#Train model and predict on test data\n",
    "lrp.fit(x_train_worklife, y_train_worklife)\n",
    "y_pred_worklife = lrp.predict(x_test_worklife)\n",
    "\n",
    "print('Accuracy score: {0:5.3f}%'.format(accuracy_score(y_pred_worklife, y_test_worklife) * 100))\n",
    "\n",
    "#Generate classification report\n",
    "print(classification_report(y_test_worklife,y_pred_worklife))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll now try to train with Random Forest Classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 8 Random Forest Classifiers took 52.736732959747314 seconds\n",
      "Best score = 0.888 +/- 0.010\n",
      "Best number of estimators = 10.000\n",
      "Accuracy score: 89.579%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       434\n",
      "          1       0.68      0.38      0.49        65\n",
      "\n",
      "avg / total       0.88      0.90      0.88       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "n_estimators = [10, 20, 50, 100, 150, 200, 250, 300]\n",
    "\n",
    "#create arrays to hold CV stats\n",
    "scr_mean_worklife_rfc = [0 for idx in range(len(n_estimators))]\n",
    "scr_std_worklife_rfc = [0 for idx in range(len(n_estimators))]\n",
    "\n",
    "for idx, n_est in enumerate(n_estimators):\n",
    "    rfcp.set_params(rfc__n_estimators = n_est)\n",
    "    score = cross_val_score(rfcp, x_train_worklife, y_train_worklife, cv=skf)\n",
    "    scr_mean_worklife_rfc[idx] = np.mean(score)\n",
    "    scr_std_worklife_rfc[idx] = np.std(score)\n",
    "    \n",
    "print('Training {} Random Forest Classifiers took {} seconds'.format(len(n_estimators), \n",
    "                                                                     str(time.time()-start_time)))\n",
    "\n",
    "idx = np.argmax(scr_mean_worklife_rfc)\n",
    "\n",
    "#display best score with error and associated 'C' value\n",
    "print('Best score = {0:5.3f} +/- {1:5.3f}'.format(scr_mean_worklife_rfc[int(idx)], \n",
    "                                                  scr_std_worklife_rfc[int(idx)]))\n",
    "print('Best number of estimators = {0:5.3f}'.format(n_estimators[int(idx)]))\n",
    "\n",
    "#set parameter to best value\n",
    "rfcp.set_params(rfc__n_estimators = n_estimators[idx])\n",
    "\n",
    "#Train model and predict on test data\n",
    "rfcp.fit(x_train_worklife, y_train_worklife)\n",
    "y_pred_worklife_rfc = lrp.predict(x_test_worklife)\n",
    "\n",
    "print('Accuracy score: {0:5.3f}%'.format(accuracy_score(y_pred_worklife_rfc, \n",
    "                                                        y_test_worklife) * 100))\n",
    "\n",
    "#Generate classification report\n",
    "print(classification_report(y_test_worklife,y_pred_worklife_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,  20,  50, 100, 150, 200, 250, 300])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Senior Management\n",
    "\n",
    "Using Logistic Regression, I see some troubling performance when classifying Senior Management. The recall for predicting Senior Management is only 0.19. While I think precision is more important for us than recall, this is still very poor performance. I will not want to use these for my final models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sm, x_test_sm, y_train_sm, y_test_sm = \\\n",
    "        train_test_split(pros_sentences_vectors_df, \n",
    "                         pros_sentences.loc[:,'Senior Management'],\n",
    "                         test_size=0.25,\n",
    "                         stratify=pros_sentences.loc[:,'Senior Management'],\n",
    "                         random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 LogisticRegression models took 9.241894721984863 seconds.\n",
      "Best score = 0.920 +/- 0.007\n",
      "Best C param = 1.000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96       456\n",
      "          1       1.00      0.19      0.31        43\n",
      "\n",
      "avg / total       0.93      0.93      0.91       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#create arrays to hold cross-validation stats\n",
    "scr_mean_sm = np.zeros(c_vals.shape)\n",
    "scr_std_sm = np.zeros(c_vals.shape)\n",
    "\n",
    "for idx, c in enumerate(c_vals):\n",
    "    lrp.set_params(lr__C = c)\n",
    "    score = cross_val_score(lrp, x_train_sm, y_train_sm, cv=skf)\n",
    "    scr_mean_sm[idx] = np.mean(score)\n",
    "    scr_std_sm[idx] = np.std(score)\n",
    "    \n",
    "print('{} LogisticRegression models took {} seconds'.format(c_vals.shape[0],\n",
    "                                                            str(time.time() - start_time))\n",
    "    \n",
    "#find best score\n",
    "idx = np.argmax(scr_mean_sm)\n",
    "\n",
    "#display best score with error and associated 'C\" value\n",
    "\n",
    "print(f'Best score = {scr_mean_sm[idx]:5.3f} +/- {scr_std_sm[idx]:5.3f}')\n",
    "print(f'Best C param = {c_vals[idx]:5.3f}')\n",
    "\n",
    "#now perform standard performance testing by creating and applying model to test data\n",
    "\n",
    "#set parameter to best value\n",
    "lrp.set_params(lr__C = c_vals[idx])\n",
    "\n",
    "#Train model and predict on test data\n",
    "lrp.fit(x_train_sm, y_train_sm)\n",
    "y_pred_sm = lrp.predict(x_test_sm)\n",
    "\n",
    "#Generate classification report\n",
    "print(classification_report(y_test_sm,y_pred_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 332.70547890663147 seconds.\n",
      "Best C param = 1.0\n",
      "Best penalty = l2\n",
      "Best CV score = 0.9203480589022758\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96       456\n",
      "          1       1.00      0.19      0.31        43\n",
      "\n",
      "avg / total       0.93      0.93      0.91       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#create arrays to hold cross-validation stats\n",
    "scr_mean_sm = np.zeros(c_vals.shape)\n",
    "scr_std_sm = np.zeros(c_vals.shape)\n",
    "\n",
    "params = dict(lr__C=c_vals, lr__penalty=['l1','l2'])\n",
    "\n",
    "gse = GridSearchCV(estimator=lrp, param_grid=params, cv=skf)\n",
    "\n",
    "gse.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "print('Took {} seconds.'.format(time.time()-start_time))\n",
    "\n",
    "print('Best C param = {}'.format(gse.best_estimator_.get_params()['lr__C']))\n",
    "print('Best penalty = {}'.format(gse.best_estimator_.get_params()['lr__penalty']))\n",
    "\n",
    "print('Best CV score = {}'.format(gse.best_score_))\n",
    "\n",
    "lrp.set_params(lr__C = gse.best_estimator_.get_params()['lr__C'], lr__penalty = gse.best_estimator_.get_params()['lr__penalty'])\n",
    "\n",
    "lrp.fit(x_train_sm, y_train_sm)\n",
    "y_pred = lrp.predict(x_test_sm)\n",
    "\n",
    "print(classification_report(y_test_sm, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification on Comp & Benefits\n",
    "\n",
    "Again, I see very poor recall of 0.19, this time when predicting 'Comp & Benefits'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cb, x_test_cb, y_train_cb, y_test_cb = \\\n",
    "        train_test_split(pros_sentences_vectors_df, \n",
    "                         pros_sentences.loc[:,'Comp & Benefits'],\n",
    "                         test_size=0.25,\n",
    "                         stratify=pros_sentences.loc[:,'Comp & Benefits'],\n",
    "                         random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 LogisticRegression models took 7.787758111953735 seconds.\n",
      "Best score = 0.920 +/- 0.007\n",
      "Best C param = 1.000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96       456\n",
      "          1       1.00      0.19      0.31        43\n",
      "\n",
      "avg / total       0.93      0.93      0.91       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#create arrays to hold cross-validation stats\n",
    "scr_mean_cb = np.zeros(c_vals.shape)\n",
    "scr_std_cb = np.zeros(c_vals.shape)\n",
    "\n",
    "for idx, c in enumerate(c_vals):\n",
    "    lrp.set_params(lr__C = c)\n",
    "    score = cross_val_score(lrp, x_train_cb, y_train_cb, cv=skf)\n",
    "    scr_mean_cb[idx] = np.mean(score)\n",
    "    scr_std_cb[idx] = np.std(score)\n",
    "    \n",
    "print('{} LogisticRegression models took {} seconds'.format(c_vals.shape[0],\n",
    "                                                            str(time.time() - start_time)) \n",
    "#find best score\n",
    "idx = np.argmax(scr_mean_sm)\n",
    "\n",
    "#display best score with error and associated 'C\" value\n",
    "\n",
    "print(f'Best score = {scr_mean_sm[idx]:5.3f} +/- {scr_std_sm[idx]:5.3f}')\n",
    "print(f'Best C param = {c_vals[idx]:5.3f}')\n",
    "\n",
    "#now perform standard performance testing by creating and applying model to test data\n",
    "\n",
    "#set parameter to best value\n",
    "lrp.set_params(lr__C = c_vals[idx])\n",
    "\n",
    "#Train model and predict on test data\n",
    "lrp.fit(x_train_sm, y_train_sm)\n",
    "y_pred_sm = lrp.predict(x_test_sm)\n",
    "\n",
    "#Generate classification report\n",
    "print(classification_report(y_test_sm,y_pred_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C param = 10.0\n",
      "Best penalty = l1\n",
      "Best CV score = 0.8078982597054887\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#create arrays to hold cross-validation stats\n",
    "scr_mean_cb = np.zeros(c_vals.shape)\n",
    "scr_std_cb = np.zeros(c_vals.shape)\n",
    "\n",
    "params = dict(lr__C=c_vals, lr__penalty=['l1','l2'])\n",
    "\n",
    "gse = GridSearchCV(estimator=lrp, param_grid=params, cv=skf)\n",
    "\n",
    "gse.fit(x_train_cb, y_train_cb)\n",
    "\n",
    "#display best score with error and associated 'C\" value\n",
    "\n",
    "print('Best C param = {}'.format(gse.best_estimator_.get_params()['lr__C']))\n",
    "print('Best penalty = {}'.format(gse.best_estimator_.get_params()['lr__penalty']))\n",
    "\n",
    "print('Best CV score = {}'.format(gse.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.93      0.87       338\n",
      "          1       0.80      0.58      0.67       161\n",
      "\n",
      "avg / total       0.82      0.82      0.81       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrp.set_params(lr__C = 10, lr__penalty = 'l1')\n",
    "\n",
    "lrp.fit(x_train_cb, y_train_cb)\n",
    "y_pred = lrp.predict(x_test_cb)\n",
    "\n",
    "print(classification_report(y_test_cb, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification on Career Opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_co, x_test_co, y_train_co, y_test_co = \\\n",
    "        train_test_split(pros_sentences_vectors_df, \n",
    "                         pros_sentences.loc[:,'Career Opportunities'],\n",
    "                         test_size=0.25,\n",
    "                         stratify=pros_sentences.loc[:,'Career Opportunities'],\n",
    "                         random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 LogisticRegression models took 6.037069797515869 seconds.\n",
      "Best score = 0.803 +/- 0.012\n",
      "Best C param = 316.228\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.95      0.91       405\n",
      "          1       0.64      0.37      0.47        94\n",
      "\n",
      "avg / total       0.82      0.84      0.82       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#create arrays to hold cross-validation stats\n",
    "scr_mean_co = np.zeros(c_vals.shape)\n",
    "scr_std_co = np.zeros(c_vals.shape)\n",
    "\n",
    "for idx, c in enumerate(c_vals):\n",
    "    lrp.set_params(lr__C = c)\n",
    "    score = cross_val_score(lrp, x_train_cb, y_train_cb, cv=skf)\n",
    "    scr_mean_co[idx] = np.mean(score)\n",
    "    scr_std_co[idx] = np.std(score)\n",
    "    \n",
    "print('{} LogisticRegression models took {} seconds'.format(c_vals.shape[0],\n",
    "                                                            str(time.time() - start_time))\n",
    "    \n",
    "#find best score\n",
    "idx = np.argmax(scr_mean_co)\n",
    "\n",
    "#display best score with error and associated 'C\" value\n",
    "\n",
    "print(f'Best score = {scr_mean_co[idx]:5.3f} +/- {scr_std_co[idx]:5.3f}')\n",
    "print(f'Best C param = {c_vals[idx]:5.3f}')\n",
    "\n",
    "#now perform standard performance testing by creating and applying model to test data\n",
    "\n",
    "#set parameter to best value\n",
    "lrp.set_params(lr__C = c_vals[idx])\n",
    "\n",
    "#Train model and predict on test data\n",
    "lrp.fit(x_train_co, y_train_co)\n",
    "y_pred_co = lrp.predict(x_test_co)\n",
    "\n",
    "#Generate classification report\n",
    "print(classification_report(y_test_co,y_pred_co))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Cons\n",
    "\n",
    "We will now do everything for CONs. This includes training a Word2Vec model and then training classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize labeled cons sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column of tokens in each sentence\n",
    "cons_sentences.loc[:,'tokens'] = cons_sentences.loc[:,'CONs_sentence'].\\\n",
    "    apply(lambda sentence: tokenize_a_sentence(sentence, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of dimensions for Word2Vec model\n",
    "dim = 100\n",
    "\n",
    "#train Word2Vec model on tokens\n",
    "model_cons = gensim.models.Word2Vec(list(cons_sentences.loc[:,'tokens']), size=dim)\n",
    "w2v_cons = dict(zip(model_cons.wv.index2word, model_cons.wv.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that it contains some commonly used words\n",
    "assert(model_cons.wv.__contains__('opportunity'))\n",
    "assert(model_cons.wv.__contains__('work'))\n",
    "assert(model_cons.wv.__contains__('benefits'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derekjung/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:11: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "/Users/derekjung/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "#store Word2Vec representation of each CON sentence\n",
    "cons_sentences_vectors_array = np.zeros((cons_sentences.shape[0], dim))\n",
    "\n",
    "for idx in range(cons_sentences.shape[0]):\n",
    "    cons_sentences_vectors_array[idx] = average_of_tokens(cons_sentences.loc[idx,'tokens'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_sentences_vectors_df = pd.DataFrame(cons_sentences_vectors_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Culture & Values with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reserve 75% of data for training\n",
    "#stratify to make sure that equal representation of Culture & Values and not in training/testing\n",
    "x_train_culture, x_test_culture, y_train_culture, y_test_culture = \\\n",
    "    train_test_split(cons_sentences_vectors_df, \n",
    "                     cons_sentences.loc[:,'Culture & Values'],\n",
    "                    test_size=0.25,\n",
    "                     stratify=cons_sentences.loc[:,'Culture & Values'],\n",
    "                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vals = np.logspace(-3,4,15)\n",
    "\n",
    "#Logistic Regression pipeline\n",
    "lrp = Pipeline([('ss', StandardScaler()),\n",
    "               ('lr', LogisticRegression(random_state=23))])\n",
    "\n",
    "#do k-fold cross-validation to maintain class balance\n",
    "skf = StratifiedKFold(n_splits=5, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 151.5967719554901 seconds.\n",
      "Best C param = 3.1622776601683795\n",
      "Best penalty = l2\n",
      "Best CV score = 0.68\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.86      0.77       328\n",
      "          1       0.53      0.31      0.39       172\n",
      "\n",
      "avg / total       0.64      0.67      0.64       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "params = dict(lr__C=c_vals, lr__penalty=['l1','l2'])\n",
    "\n",
    "gse = GridSearchCV(estimator=lrp, param_grid=params, cv=skf)\n",
    "\n",
    "gse.fit(x_train_culture, y_train_culture)\n",
    "\n",
    "print('Took {} seconds.'.format(time.time()-start_time))\n",
    "\n",
    "print('Best C param = {}'.format(gse.best_estimator_.get_params()['lr__C']))\n",
    "print('Best penalty = {}'.format(gse.best_estimator_.get_params()['lr__penalty']))\n",
    "\n",
    "print('Best CV score = {}'.format(gse.best_score_))\n",
    "\n",
    "lrp.set_params(lr__C = gse.best_estimator_.get_params()['lr__C'], lr__penalty = gse.best_estimator_.get_params()['lr__penalty'])\n",
    "\n",
    "lrp.fit(x_train_culture, y_train_culture)\n",
    "y_pred = lrp.predict(x_test_culture)\n",
    "\n",
    "print(classification_report(y_test_culture, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Culture & Values', 'Work/Life Balance', 'Senior Management', \n",
    "              'Comp & Benefits', 'Career Opportunities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Culture & Values\n",
      "Best C param = 3.1622776601683795\n",
      "Best penalty = l2\n",
      "Best CV score = 0.68\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.86      0.77       328\n",
      "          1       0.53      0.31      0.39       172\n",
      "\n",
      "avg / total       0.64      0.67      0.64       500\n",
      "\n",
      "Took 134.52920722961426 seconds.\n",
      "--------------------------------------------------\n",
      "Work/Life Balance\n",
      "Best C param = 1.0\n",
      "Best penalty = l2\n",
      "Best CV score = 0.8946666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       441\n",
      "          1       0.57      0.22      0.32        59\n",
      "\n",
      "avg / total       0.86      0.89      0.87       500\n",
      "\n",
      "Took 130.51529574394226 seconds.\n",
      "--------------------------------------------------\n",
      "Senior Management\n",
      "Best C param = 10.0\n",
      "Best penalty = l1\n",
      "Best CV score = 0.8886666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       424\n",
      "          1       0.63      0.42      0.50        76\n",
      "\n",
      "avg / total       0.86      0.87      0.86       500\n",
      "\n",
      "Took 219.09891724586487 seconds.\n",
      "--------------------------------------------------\n",
      "Comp & Benefits\n",
      "Best C param = 3.1622776601683795\n",
      "Best penalty = l2\n",
      "Best CV score = 0.8846666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       426\n",
      "          1       0.91      0.27      0.42        74\n",
      "\n",
      "avg / total       0.89      0.89      0.86       500\n",
      "\n",
      "Took 200.7047369480133 seconds.\n",
      "--------------------------------------------------\n",
      "Career Opportunities\n",
      "Best C param = 1.0\n",
      "Best penalty = l2\n",
      "Best CV score = 0.8393333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.92       417\n",
      "          1       0.72      0.16      0.26        83\n",
      "\n",
      "avg / total       0.83      0.85      0.81       500\n",
      "\n",
      "Took 230.27377200126648 seconds.\n"
     ]
    }
   ],
   "source": [
    "#train Logistic Regression with Stratified K-fold and GridSearch on every category\n",
    "for cat in categories:\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    print('-'*50)\n",
    "    print(cat)\n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(cons_sentences_vectors_df,\n",
    "                     cons_sentences.loc[:,cat],\n",
    "                     test_size=0.25,\n",
    "                     stratify=cons_sentences.loc[:,cat],\n",
    "                     random_state=23)\n",
    "    \n",
    "\n",
    "    params = dict(lr__C=c_vals, lr__penalty=['l1','l2'])\n",
    "\n",
    "    gse = GridSearchCV(estimator=lrp, param_grid=params, cv=skf)\n",
    "\n",
    "    gse.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    print('Best C param = {}'.format(gse.best_estimator_.get_params()['lr__C']))\n",
    "    print('Best penalty = {}'.format(gse.best_estimator_.get_params()['lr__penalty']))\n",
    "\n",
    "    print('Best CV score = {}'.format(gse.best_score_))\n",
    "\n",
    "    lrp.set_params(lr__C = gse.best_estimator_.get_params()['lr__C'], lr__penalty = gse.best_estimator_.get_params()['lr__penalty'])\n",
    "\n",
    "    lrp.fit(x_train, y_train)\n",
    "    y_pred = lrp.predict(x_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print('Took {} seconds.'.format(time.time()-start_time))\n",
    "    \n",
    "    start_time = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
